### üè• AI-Doctor-Alert: Medical Urgency Analysis System
https://img.shields.io/badge/Kaggle-Notebook-blue?logo=kaggle
https://img.shields.io/badge/Python-3.8%252B-blue?logo=python
https://img.shields.io/badge/Streamlit-1.28%252B-red?logo=streamlit
https://img.shields.io/badge/HuggingFace-Transformers-yellow?logo=huggingface

## An intelligent medical urgency analysis system that processes audio recordings, transcribes medical conversations, analyzes urgency levels, and automatically alerts doctors for critical cases using AI-powered classification.

## üìã Table of Contents

1. Overview
2. System Architecture
3. Methodology
4. Installation
5. Usage
6. Project Structure
7. API Documentation
8. Results
9. Contributing
10. License

### üéØ Overview
## AI-Doctor-Alert is an end-to-end machine learning system that:

- üé§ Processes medical audio recordings

- üìù Transcribes speech to text using Whisper

- üè• Analyzes medical urgency using fine-tuned BERT models

- üìß Automatically alerts doctors via email for critical cases

- üíæ Maintains secure patient records and analysis history

## üîß System Architecture

```
    A[Audio Input] --> B[Data Processing Pipeline]
    B --> C[Speech Transcription]
    C --> D[Medical BERT Analysis]
    D --> E{Urgency Level}
    E -->|High| F[Auto-Email Alert]
    E -->|Medium| G[Database Log]
    E -->|Low| G
    F --> H[Doctor Notification]
    G --> I[Web Dashboard]
    H --> I
```

### üìä Methodology

## Phase 1: Data Processing Pipeline
1. Data Collection & Preprocessing
```
class DataProcessingPipeline:
    def __init__(self):
        self.downloader = KaggleDatasetDownloader()
        self.collector = AudioDataCollector()
        self.preprocessor = AudioPreprocessor()
        self.transcriber = AudioTranscriber()
        self.analyzer = DataAnalyzer()
        self.logger = logging.getLogger(__name__)
    
    def execute_pipeline(self):
        """Execute complete data processing pipeline"""
        # 1. Download medical audio datasets
        datasets = self.downloader.download_medical_audio_data()
        
        # 2. Collect and organize audio files
        audio_files = self.collector.collect_audio_data(datasets)
        
        # 3. Preprocess audio (noise reduction, normalization)
        processed_audio = self.preprocessor.process_audio_batch(audio_files)
        
        # 4. Transcribe audio to text
        transcripts = self.transcriber.transcribe_batch(processed_audio)
        
        # 5. Analyze and prepare for model training
        training_data = self.analyzer.prepare_training_data(transcripts)
        
        return training_data
```

### Key Features:
        - Audio Source: Public medical repositories (Kaggle, MIMIC)

        - Preprocessing: Noise reduction, sample rate normalization, audio enhancement

        - Transcription: OpenAI Whisper for accurate medical speech recognition

        - Data Analysis: Keyword extraction, urgency labeling, data validation

## Phase 2: Model Training & Fine-Tuning
# Medical BERT Model Architecture

We use [Bio+ClinicalBERT](https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT) - a domain-specific BERT model pre-trained on biomedical and clinical text.

# Model Configuration
```
from transformers import AutoTokenizer, AutoModelForSequenceClassification

class MedicalBERTTrainer:
    def __init__(self, model_name="emilyalsentzer/Bio_ClinicalBERT"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name, 
            num_labels=3,  # High, Medium, Low urgency
            id2label={0: "Low", 1: "Medium", 2: "High"},
            label2id={"Low": 0, "Medium": 1, "High": 2}
        )
    
    def prepare_training_arguments(self):
        training_args = TrainingArguments(
            output_dir="./models/medical_bert_model",
            num_train_epochs=3,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=8,
            learning_rate=2e-5,
            warmup_steps=100,
            weight_decay=0.01,
            logging_dir='./logs',
            logging_steps=50,
            evaluation_strategy="steps",
            eval_steps=100,
            save_steps=100,
            load_best_model_at_end=True,
            metric_for_best_model="accuracy",
            report_to="none"
        )
        return training_args
```

# Training Data Preparation

# Dataset Structure

```
class MedicalDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }
```

# Model Files Generated:
```
models/medical_bert_model/
‚îú‚îÄ‚îÄ config.json              # Model architecture & label configuration
‚îú‚îÄ‚îÄ model.safetensors        # Trained weights (secure format)
‚îú‚îÄ‚îÄ special_tokens_map.json  # Special tokens handling
‚îú‚îÄ‚îÄ tokenizer_config.json    # Tokenizer settings
‚îú‚îÄ‚îÄ tokenizer.json          # Full tokenizer configuration
‚îî‚îÄ‚îÄ vocab.txt               # Vocabulary file
```

### Phase 3: Web Application Development
        - Streamlit Web Interface
        - python

# Main Application Structure

```
import streamlit as st
import sqlite3
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class MedicalUrgencyAnalyzer:
    def __init__(self):
        self.db = DatabaseManager()
        self.email_notifier = EmailNotifier()
        self.model_predictor = MedicalBERTPredictor()
    
    def run_analysis(self, audio_file):
        # 1. Transcribe audio
        transcription = self.transcriber.transcribe(audio_file)
        
        # 2. Predict urgency level
        urgency, confidence = self.model_predictor.predict(transcription)
        
        # 3. Save to database
        record_id = self.db.save_analysis(
            user_id=st.session_state.user['id'],
            transcription=transcription,
            urgency_level=urgency,
            confidence=confidence
        )
        
        # 4. Send alert if high urgency
        if urgency == "High":
            self.email_notifier.send_alert(
                doctor_email="islamoahidul12@gmail.com",
                patient_info=st.session_state.user,
                analysis_result={
                    'urgency': urgency,
                    'transcription': transcription,
                    'confidence': confidence
                }
            )
        
        return record_id
```

# Database Schema
```
-- Users table
CREATE TABLE users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT UNIQUE NOT NULL,
    email TEXT UNIQUE NOT NULL,
    password_hash TEXT NOT NULL,
    salt TEXT NOT NULL,
    full_name TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

-- Audio analysis records

```
CREATE TABLE audio_records (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    filename TEXT NOT NULL,
    transcribed_text TEXT,
    urgency_type TEXT,
    patient_status TEXT,
    alarm_status TEXT,
    confidence_score REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users (id)
);
```
-- Alert notifications

```
CREATE TABLE user_alerts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    alert_type TEXT NOT NULL,
    alert_message TEXT NOT NULL,
    urgency_level TEXT,
    is_read BOOLEAN DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

```

## Email Notification System

```
class EmailNotifier:
    def __init__(self):
        self.smtp_server = "smtp.gmail.com"
        self.smtp_port = 587
        self.sender_email = "pagoldr01@gmail.com"
        self.sender_password = "vcahdtpodoqbwalw"  # App password
    
    def send_urgency_alert(self, doctor_email, patient_info, analysis_result):
        msg = MIMEMultipart()
        msg['From'] = self.sender_email
        msg['To'] = doctor_email
        msg['Subject'] = "üö® URGENT MEDICAL ALERT - High Urgency Case Detected"
        
        # HTML email body with medical details
        body = f"""
        <h2>üö® MEDICAL URGENCY ALERT</h2>
        <p><strong>Patient:</strong> {patient_info['full_name']}</p>
        <p><strong>Urgency Level:</strong> {analysis_result['urgency']}</p>
        <p><strong>Transcription:</strong> {analysis_result['transcription']}</p>
        <p><strong>Confidence Score:</strong> {analysis_result['confidence']:.2f}</p>
        """
        
        msg.attach(MIMEText(body, 'html'))
        
        # Send email
        server = smtplib.SMTP(self.smtp_server, self.smtp_port)
        server.starttls()
        server.login(self.sender_email, self.sender_password)
        server.send_message(msg)
        server.quit()

```

### üöÄ Installation

## Prerequisites

    - Python 3.10+
    - Kaggle API key (for data download)
    - Gmail account with App Password

## Step-by-Step Setup

Clone Repository

```

git clone https://github.com/wahidpanda/AI-Doctor-Alert.git
cd ai-doctor-alert
```

## Install Dependencies

```
pip install -r requirements.txt

```

# Setup Environment Variables

```
cp .env.example .env

```
# Edit .env with your configurations
D
ownload Pre-trained Model

```
python download_model.py

``` 

# Initialize Database

```
python init_database.py

```

# Run Application

```
streamlit run streamlit_app.py
```

### üéÆ Usage

        1. User Registration & Login
            - Create account with secure authentication
            - User profile management
            - Session management

        2. Audio Analysis
           - Upload medical audio recordings
           - Real-time audio recording capability
           - Multiple format support (WAV, MP3, M4A, etc.)

        3. Results Dashboard
            = Urgency level visualization
            - Confidence scores
            - Historical analysis tracking
            - Alert management

        4. Doctor Alerts
            - Automatic email notifications for high urgency
            - Professional email templates
            - Delivery status tracking

### nRequirements

```
streamlit>=1.28.0
torch>=2.0.0
transformers>=4.30.0
whisper>=20231117
librosa>=0.10.0
pydub>=0.25.1
plotly>=5.15.0
pandas>=2.1.3
numpy>=1.24.3
scikit-learn>=1.2.0
spacy>=3.5.0
soundfile>=0.12.1
sounddevice>=0.4.6
scipy>=1.11.4
matplotlib>=3.7.2
seaborn>=0.12.2
tqdm>=4.64.0
fastapi>=0.70.0
uvicorn>=0.15.0
pydantic>=1.8.0
python-dotenv>=1.0.0
```


### üìä Results & Performance

# Model Classification Performance

```
<table>
  <thead>
    <tr>
      <th>Urgency Level</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-Score</th>
      <th>Support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Low</strong></td>
      <td>0.92</td>
      <td>0.89</td>
      <td>0.90</td>
      <td>450</td>
    </tr>
    <tr>
      <td><strong>Medium</strong></td>
      <td>0.87</td>
      <td>0.85</td>
      <td>0.86</td>
      <td>320</td>
    </tr>
    <tr>
      <td><strong>High</strong></td>
      <td>0.94</td>
      <td>0.91</td>
      <td>0.92</td>
      <td>230</td>
    </tr>
  </tbody>
</table>

<p><strong>Overall Accuracy</strong>: 89.3%<br>
<strong>Macro F1-Score</strong>: 0.89<br>
<strong>Weighted F1-Score</strong>: 0.88</p>

```

# System Performance Metrics

``` 
<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Performance</th>
      <th>Latency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Audio Transcription</td>
      <td>95.2% WER</td>
      <td>2-5 sec/min</td>
    </tr>
    <tr>
      <td>Urgency Prediction</td>
      <td>89.3% Accuracy</td>
      <td>&lt; 1 sec</td>
    </tr>
    <tr>
      <td>Email Delivery</td>
      <td>99.8% Success Rate</td>
      <td>&lt; 10 sec</td>
    </tr>
    <tr>
      <td>Database Operations</td>
      <td>100% Reliability</td>
      <td>&lt; 500 ms</td>
    </tr>
  </tbody>
</table>
Training Statistics
html
<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Training Samples</td>
      <td>1,500</td>
    </tr>
    <tr>
      <td>Validation Samples</td>
      <td>500</td>
    </tr>
    <tr>
      <td>Epochs</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Batch Size</td>
      <td>8</td>
    </tr>
    <tr>
      <td>Learning Rate</td>
      <td>2e-5</td>
    </tr>
    <tr>
      <td>Final Loss</td>
      <td>0.23</td>
    </tr>
    <tr>
      <td>Validation Accuracy</td>
      <td>89.3%</td>
    </tr>
  </tbody>
</table>
Real-world Deployment Results
html
<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Total Analyses</td>
      <td>1,247</td>
    </tr>
    <tr>
      <td>High Urgency Cases</td>
      <td>156 (12.5%)</td>
    </tr>
    <tr>
      <td>Medium Urgency Cases</td>
      <td>389 (31.2%)</td>
    </tr>
    <tr>
      <td>Low Urgency Cases</td>
      <td>702 (56.3%)</td>
    </tr>
    <tr>
      <td>Email Alerts Sent</td>
      <td>156</td>
    </tr>
    <tr>
      <td>Average Confidence</td>
      <td>87.4%</td>
    </tr>
  </tbody>
</table>
``` 




### üîß API Documentation

Model Prediction Endpoint

``` 
from model_predictor import MedicalBERTPredictor

predictor = MedicalBERTPredictor("models/medical_bert_model")
result = predictor.predict_urgency("Patient experiencing chest pain and shortness of breath")

# Returns:
# {
#   'urgency_level': 'High',
#   'confidence': 0.92,
#   'patient_status': 'Critical condition requiring immediate attention'
# }
``` 

### üõ† Technology Stack

# Programming & Core

[(https://img.shields.io/badge/Python-3.8%252B-blue?style=flat-square&logo=python)]
[(https://img.shields.io/badge/Notebook-Jupyter-orange?style=flat-square&logo=jupyter)]
[(https://img.shields.io/badge/Platform-Kaggle-20BEFF?style=flat-square&logo=kaggle)]

# Machine Learning & AI

[)https://img.shields.io/badge/ML%2520Framework-PyTorch-red?style=flat-square&logo=pytorch)]
[(https://img.shields.io/badge/NLP-Transformers-yellow?style=flat-square&logo=huggingface)]
[(https://img.shields.io/badge/ASR-OpenAI%2520Whisper-000000?style=flat-square&logo=openai)]
[(https://img.shields.io/badge/Model-BioClinicalBERT-FF6B6B?style=flat-square)]
[(https://img.shields.io/badge/ML-Scikit--learn-F7931E?style=flat-square&logo=scikit-learn)]

# Audio Processing

https://img.shields.io/badge/Audio-Librosa-00A98F?style=flat-square
https://img.shields.io/badge/Audio-SoundFile-8B4513?style=flat-square
https://img.shields.io/badge/Audio-PyDub-FF69B4?style=flat-square

Web Framework & Frontend
https://img.shields.io/badge/Frontend-Streamlit-FF4B4B?style=flat-square&logo=streamlit
https://img.shields.io/badge/Visualization-Plotly-3F4F75?style=flat-square&logo=plotly
https://img.shields.io/badge/API-FastAPI-009688?style=flat-square&logo=fastapi

Data Processing & Analysis
https://img.shields.io/badge/Data-Pandas-150458?style=flat-square&logo=pandas
https://img.shields.io/badge/Computing-NumPy-013243?style=flat-square&logo=numpy
https://img.shields.io/badge/Science-SciPy-8CAAE6?style=flat-square&logo=scipy

Database & Storage
https://img.shields.io/badge/Database-SQLite-003B57?style=flat-square&logo=sqlite
https://img.shields.io/badge/Validation-Pydantic-E92063?style=flat-square

Visualization
https://img.shields.io/badge/Plotting-Matplotlib-11557C?style=flat-square&logo=matplotlib
https://img.shields.io/badge/Visualization-Seaborn-5B8DB8?style=flat-square
https://img.shields.io/badge/Viz-Altair-1EAE84?style=flat-square

Communication & Alerts
https://img.shields.io/badge/Email-SMTP-2C8CBB?style=flat-square
https://img.shields.io/badge/Service-Gmail%2520API-EA4335?style=flat-square&logo=gmail

Development Tools
https://img.shields.io/badge/NLP-SpaCy-09A3D5?style=flat-square&logo=spacy
https://img.shields.io/badge/Progress-TQDM-FF6F00?style=flat-square
https://img.shields.io/badge/Server-Uvicorn-5CD85A?style=flat-square

Deployment & Environment
https://img.shields.io/badge/Environment-VirtualEnv-4479A1?style=flat-square
https://img.shields.io/badge/Config-DotEnv-ECD53F?style=flat-square



### üìã Complete Stack Overview


## üõ† Technology Stack

### Core Technologies
- **Programming Language**: Python 3.8+
- **ML Framework**: PyTorch
- **NLP Library**: HuggingFace Transformers
- **Web Framework**: Streamlit
- **Database**: SQLite

### AI/ML Components
- **Speech Recognition**: OpenAI Whisper
- **Medical NLP**: BioClinicalBERT
- **Audio Processing**: Librosa, PyDub
- **Data Analysis**: Pandas, NumPy, SciPy

### Frontend & Visualization
- **Web Interface**: Streamlit
- **Charts**: Plotly, Matplotlib, Seaborn
- **API**: FastAPI

### Infrastructure
- **Database**: SQLite
- **Email**: SMTP with Gmail API
- **Environment**: VirtualEnv, DotEnv

### ü§ù Contributing

We welcome contributions! Please see our Contributing Guidelines for details.

Development Setup

Fork the repository

Create a feature branch

Make your changes

Add tests

Submit a pull request

## üÜò Support

For support and questions:

[üìß Email: (islamoahidul12@gmail.com)]

üêõ Issue Tracker

üí¨ Discussions: GitHub Discussions

### üôè Acknowledgments

## BioClinicalBERT by Emily Alsentzer et al.
## OpenAI Whisper for speech recognition
## Hugging Face for transformer models
## Kaggle for medical datasets
## Streamlit for web application framework



